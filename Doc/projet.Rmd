---
title: "Projet"
output: 
  html_document:
    css: style.css
---

```{r, include = FALSE}

# Paramètres pour le .Rmd ------------------------------------------------------


knitr::opts_chunk$set(
   echo = FALSE,
   align = "c"
)


# Chemins d'accès --------------------------------------------------------------


path_data <- "../Data"
path_obj <- "../inst"
path_fct <- "../R"


# Charger les objets -----------------------------------------------------------


rf_model <- readRDS(file.path(path_obj, "s5_random_forest.rds"))
pca <- readRDS(file.path(path_obj, "s4_pca.rds"))


# Charger les fonctions utiles -------------------------------------------------


source(file.path(path_fct, "utils.R"))

```

# Contexte et objectifs (1/2 page)

- Contexte
- Objectifs
- Hypothèses

# Préparation et nettoyage des données (1 page)

- Source
- Description
- Type de variables
- Vérifier les doublons
- Vérifier les erreurs de saisie
- Uniformisation des valeurs
- Validation de fusion de tables

# Analyse descriptive et exploratoire (2-3 pages)

- Type d’échantillon
- Nombre d'observations et variables
- Analyse descriptive uni et multivariées
- Identification des valeurs extrêmes et aberrantes (+ traitées)
- Gestion des données manquantes 
Doit se faire sur la jeu de données d'entraînement (voir p.245 ESL)
- Création de nouvelles variables
- Identification de la dépendance
- Pré-sélection de variables
- Identification d'interactions possibles

## Préselection de variables 

Pour modéliser le débit d'eau des rivières, nous allons utiliser un modèle mixte. Les détails expliquant le choix de ce type de modèle se trouve dans la section suivante. Toutefois, une caractéristique importante à soulever concernant ce modèle est qu'il a la caractéristique de ne pas bien tolérer la haute dimensionnalité (<span style="color:red">mettre une référence</span>). Ainsi, comme notre jeu de données contient plusieurs variables (~50), nous faisons, avant l'étape de modélisation, une préselection de variables. Pour ce faire, nous faisons une analyse des composantes principales pour orthogonaliser les variables explicatives et nous défaire de la multicolinéarité. Par la suite, nous entraînons une forêt aléatoire pour faire une sélection basée sur l'importance des variables.

Nous faisons l'analyse des composantes principales en premier étant donné que si nous avons deux variables fortement corrélées (linéairement) entre elles, le niveau d'importance de l'effet sur la variable réponse de ces variables sera, d'une certaine manière, dilué aux travers les variables corrélées. L'impact de ceci est que plusieurs variables qui sont corrélées fortement ensemble peuvent sembler moins importantes que si nous avions conservé qu'une seule variable.

- Analyse des composantes principales

Nous faisons, donc, une anlyse des composantes principales avec la fonction `PCA` de la librairie `FactoMineR`. Celle-ci standardise, par défaut, nos variables. L'objectif de cette analyse des composantes principales est de faire une première sélection des variables pas trop sévère et, surtout, retirer certaines variables fortement linéairement corrélées.

Nous pouvons, toutefois, regarder le nombre de composantes nécessaire pour expliquer 90% de la variabilité de nos données. On observe dans le graphique suivant qu'il faudrait les 18 premières composantes.

```{r}


# Afficher la variance cumulée expliquée par composante
graph_pca_var_cum(pca, threshold = 0.9)


```

Si nous utilisons plutôt la règle de Cattell, pour faire cette sélection, on obtiendrait une valeur quelques peu supérieur, soit un peu au dessus de 20.

```{r}


# Afficher le graphique pour appliquer la règle de Cattell
graph_cattell(pca)


```

Nous allons afficher les deux premières composantes avec la variable de débit (qui n'a pas été inclut dans cette analyse des composantes principales).

```{r}


# Afficher les deux premières composantes
graph_pca(pca)


```

- Forêt aléatoire 

Il est à noter que cette étape se fait sur le jeu d'entraînement seulement. En effet, comme il est mentionné, dans _Element of Statistical Learning_ (_ELS_)^[The elements of statistical learning : data mining, inference, and prediction, p. 245], l'objectif, dans une stratégie de validation, est d'avoir un jeu de données de test qui est indépendant du modèle que l'on entraîne. Or, si nous faisons la sélection des variables explicatives, sur l'ensemble de notre jeu de données, cette indépendance ne sera pas respectée puisque le modèle sera basé sur des variables explicatives qui ont été sélectionnées partiellement à partir du jeu de test. 

La forêt aléatoire entraînée pour la préselection a été construite à partir de la librairie R _ranger_ (pour avoir de détails sur la méthodologie, se réfèrer à l'annexe). L'importance des variables est obtenu à partir de la permutation des variables explicatives du jeu de données _Out of the Bag_ (OOB). Comme décrit dans _ELS_^[The elements of statistical learning : data mining, inference, and prediction, p. 593], l'idée générale est que, pour chaque arbre, nous avons un jeu de donnée laissé à part (OOB) que nous utilisons pour calculer, pour chaque variable explicatives, l'augmentation de l'erreur ou la diminution de l'exactitude entre les prédictions du jeu de données non-modifié et celles du jeu de données où nous permutons les valeurs de la variable évaluée. À chaque itération, en venant calculer l'impact sur un jeu de données indépendant des données vues par l'arbre entraîné, nous avons un portrait adéquat des variables importantes en généralisation, et non, importantes pour entraîner le modèle. Dans la librairie _ranger_, l'importance des variables est calculé à partir de la méthode décrite dans l'article _A computationally fast variable importance test for random forests for high-dimensional data. Adv Data Anal Classif_^[Janitza, S., Celik, E. & Boulesteix, A.-L., (2015). A computationally fast variable importance test for random forests for high-dimensional data. Adv Data Anal Classif doi: 10.1007/s116340160276- 4].

<span style="color:red">Quelle mesure de performance pour l'importance? Comment l'interpréter? À ajouter pour trouver les limites possibles</span>
      
Nous affichons les 15 variables les plus importantes basée sur la méthode précédemment décrite :

```{r}


# Afficher les variables importantes
show_imp_var(rf_model$fit, nb_var = 15)


```

**Constats :**

Les trois variables qui ont le plus d'importance selon ce modèle et cette méthode pour calculer l'importance des variables sont liées aux caractéristiques de la rivière. Les deux premières, soient le volume et l'aire de la rivière, sont probablement fortement corrélées. L'analyse des composantes principales pourra nous indiquer si c'est le cas et si nous devons garder les deux. Par ailleurs, nous voyons que nous avons par deux fois la variable de précipitations printanières moyennes : une fois pour le mois d'avril et une autre fois pour le mois de mars. Encore une fois, il est fort probable que ces deux soient corrélées et nous validerons si c'est le cas.

Pour sélectionner les variables, plusieurs options s'offrent à nous. Nous pouvons sélectionner soient un nombre fixé de variables explicatives. Également, nous pourrions couper à partir d'un certain seuil d'importance de variable. 

# Modélisation et validation (1-2 pages)

- Pertinence du modèle
- Choix des hyperparamètres + stratégie de validation
- Choix des métriques

# Analyse, discussion et conclusion (2-3 pages)

- Performance des modèles
- Enjeux éthiques
- Recommandation du modèle? 

# Annexe

